{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7cea5e",
   "metadata": {},
   "source": [
    "# **Tugas Praktikum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba094a",
   "metadata": {},
   "source": [
    "# **Langkah 1: Pemuatan Data**\n",
    "\n",
    "Langkah awal adalah memuat dataset dari file wbc.csv menggunakan library Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil dimuat.\n",
      "Dimensi data awal: (569, 33)\n",
      "\n",
      "Info dataset awal:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Impor library yang dibutuhkan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Memuat Data ---\n",
    "try:\n",
    "    df = pd.read_csv('/content/wbc.csv')\n",
    "    print(\"Dataset berhasil dimuat.\")\n",
    "    print(\"Dimensi data awal:\", df.shape)\n",
    "    print(\"\\nInfo dataset awal:\")\n",
    "    df.info()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'wbc.csv' tidak ditemukan. Mohon periksa kembali path file Anda.\")\n",
    "    # Jika file tidak ditemukan, hentikan eksekusi lebih lanjut.\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff5a27",
   "metadata": {},
   "source": [
    "# **Langkah 2: Pemisahan Variabel (Pembersihan Data)**\n",
    "\n",
    "Pada tahap ini, dilakukan identifikasi dan pemisahan antara variabel yang relevan dan tidak relevan untuk pemodelan. Kolom yang tidak memiliki nilai prediktif akan dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fd6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kolom 'id' telah dihapus.\n",
      "Kolom 'Unnamed: 32' telah dihapus.\n",
      "\n",
      "Data setelah penghapusan kolom (5 baris pertama):\n",
      "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0         M        17.99         10.38          122.80     1001.0   \n",
      "1         M        20.57         17.77          132.90     1326.0   \n",
      "2         M        19.69         21.25          130.00     1203.0   \n",
      "3         M        11.42         20.38           77.58      386.1   \n",
      "4         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Membersihkan dan Memisahkan Variabel ---\n",
    "# Menghapus kolom 'id' karena tidak relevan untuk pemodelan\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "    print(\"\\nKolom 'id' telah dihapus.\")\n",
    "\n",
    "# Menghapus kolom 'Unnamed: 32' yang sering muncul karena kesalahan format CSV\n",
    "if 'Unnamed: 32' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 32'])\n",
    "    print(\"Kolom 'Unnamed: 32' telah dihapus.\")\n",
    "\n",
    "print(\"\\nData setelah penghapusan kolom (5 baris pertama):\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabdbddb",
   "metadata": {},
   "source": [
    "# **Langkah 3: Encoding Kolom \"diagnosis\"**\n",
    "\n",
    "Kolom target diagnosis berisi data kategorikal ('M' dan 'B') yang perlu diubah menjadi format numerik agar dapat diproses oleh algoritma machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c40dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kolom 'diagnosis' setelah encoding (5 baris pertama):\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: diagnosis, dtype: int64\n",
      "\n",
      "Mapping diagnosis: M (Malignant) -> 1, B (Benign) -> 0\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Encoding Kolom 'diagnosis' ---\n",
    "# Mengubah label 'M' (Malignant) dan 'B' (Benign) menjadi nilai numerik (1 dan 0)\n",
    "label_encoder = LabelEncoder()\n",
    "df['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n",
    "print(\"\\nKolom 'diagnosis' setelah encoding (5 baris pertama):\")\n",
    "print(df['diagnosis'].head())\n",
    "print(\"\\nMapping diagnosis: M (Malignant) -> 1, B (Benign) -> 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a0b64",
   "metadata": {},
   "source": [
    "# **Langkah 4: Standarisasi Kolom Numerik**\n",
    "\n",
    "Fitur-fitur numerik dalam dataset memiliki skala dan rentang nilai yang sangat beragam. Standarisasi diperlukan untuk menyamakan skala ini, sehingga tidak ada satu fitur pun yang mendominasi proses pembelajaran model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96949b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data fitur setelah standarisasi (5 baris pertama):\n",
      "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
      "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
      "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
      "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
      "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
      "\n",
      "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0          3.283515        2.652874             2.532475       2.217515   \n",
      "1         -0.487072       -0.023846             0.548144       0.001392   \n",
      "2          1.052926        1.363478             2.037231       0.939685   \n",
      "3          3.402909        1.915897             1.451707       2.867383   \n",
      "4          0.539340        1.371011             1.428493      -0.009560   \n",
      "\n",
      "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
      "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
      "2               -0.398008  ...      1.511870      -0.023974         1.347475   \n",
      "3                4.910919  ...     -0.281464       0.133984        -0.249939   \n",
      "4               -0.562450  ...      1.298575      -1.466770         1.338539   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0    2.001237          1.307686           2.616665         2.109526   \n",
      "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
      "2    1.456285          0.527407           1.082932         0.854974   \n",
      "3   -0.550021          3.394275           3.893397         1.989588   \n",
      "4    1.220724          0.220556          -0.313395         0.613179   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              2.296076        2.750622                 1.937015  \n",
      "1              1.087084       -0.243890                 0.281190  \n",
      "2              1.955000        1.152255                 0.201391  \n",
      "3              2.175786        6.046041                 4.935010  \n",
      "4              0.729259       -0.868353                -0.397100  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Standarisasi Kolom Numerik ---\n",
    "# Memisahkan fitur (X) dan target (y)\n",
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Membuat objek StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Melakukan standarisasi pada semua kolom fitur\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Mengubah kembali hasil standarisasi ke dalam bentuk DataFrame agar mudah dibaca\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nData fitur setelah standarisasi (5 baris pertama):\")\n",
    "print(X_scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3031898",
   "metadata": {},
   "source": [
    "# **Langkah 5: Pembagian Data (Stratified Split)**\n",
    "\n",
    "Dataset yang telah bersih dan terstandarisasi dibagi menjadi dua set: data latih (training set) dan data uji (testing set) dengan rasio 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cce497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hasil Pembagian Data ---\n",
      "Ukuran data fitur latih (X_train): (455, 30)\n",
      "Ukuran data fitur uji (X_test):   (114, 30)\n",
      "Ukuran data target latih (y_train): (455,)\n",
      "Ukuran data target uji (y_test):   (114,)\n",
      "\n",
      "Proporsi diagnosis di data latih (y_train):\n",
      "diagnosis\n",
      "0    0.626374\n",
      "1    0.373626\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Proporsi diagnosis di data uji (y_test):\n",
      "diagnosis\n",
      "0    0.631579\n",
      "1    0.368421\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Pembagian Data (Stratified Split) ---\n",
    "# Membagi data menjadi 80% data latih dan 20% data uji\n",
    "# 'stratify=y' memastikan proporsi kelas target (diagnosis) sama di data latih dan uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled_df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n--- Hasil Pembagian Data ---\")\n",
    "print(\"Ukuran data fitur latih (X_train):\", X_train.shape)\n",
    "print(\"Ukuran data fitur uji (X_test):  \", X_test.shape)\n",
    "print(\"Ukuran data target latih (y_train):\", y_train.shape)\n",
    "print(\"Ukuran data target uji (y_test):  \", y_test.shape)\n",
    "\n",
    "# Memeriksa proporsi kelas pada data latih dan uji\n",
    "print(\"\\nProporsi diagnosis di data latih (y_train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nProporsi diagnosis di data uji (y_test):\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
