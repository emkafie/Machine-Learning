{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/oliNd6QJO9RkT57yaau+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emkafie/Machine-Learning/blob/main/P3_JS09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Praktikum 3**"
      ],
      "metadata": {
        "id": "G1hW2oA--ZqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langkah 1**"
      ],
      "metadata": {
        "id": "z5kKNqhT-ZeD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z2CW_GA--RwL"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# IMPORT LIBRARY\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# LANGKAH 1: LOAD DATA\n",
        "# ==========================================\n",
        "# Menggunakan encoding 'latin-1' karena dataset SMS sering mengandung karakter spesial\n",
        "try:\n",
        "    df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "    print(\"Data berhasil di-load!\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"File 'spam.csv' tidak ditemukan. Pastikan file ada di direktori yang sama.\")\n",
        "    # Keluar dari program jika file tidak ada untuk mencegah error selanjutnya\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdlA8KxA--W1",
        "outputId": "06d33381-9462-4c71-dd18-549ea6a56470"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data berhasil di-load!\n",
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langkah 2**"
      ],
      "metadata": {
        "id": "Xkhnb1kz_iFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# LANGKAH 2: PREPROCESSING\n",
        "# ==========================================\n",
        "\n",
        "# 1. Drop 3 kolom terakhir yang tidak berguna (Unnamed)\n",
        "df = df.drop(df.iloc[:,2:], axis=1)\n",
        "\n",
        "# 2. UBAH NAMA KOLOM (Penting agar langkah selanjutnya berjalan)\n",
        "# Mengubah v1 menjadi 'Labels' dan v2 menjadi 'SMS'\n",
        "df.rename(columns={'v1': 'Labels', 'v2': 'SMS'}, inplace=True)\n",
        "\n",
        "# 3. Inspeksi Data\n",
        "print(\"\\n--- Inspeksi Data ---\")\n",
        "print(df['Labels'].value_counts())\n",
        "print(\"\\nDeskripsi Data:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 4. Encoding Label\n",
        "# spam = 1, ham = 0\n",
        "new_labels = {\n",
        "    'spam': 1,\n",
        "    'ham': 0\n",
        "}\n",
        "df['Labels'] = df['Labels'].map(new_labels)\n",
        "\n",
        "# 5. Memisahkan Fitur (X) dan Label (y)\n",
        "X = df['SMS'].values\n",
        "y = df['Labels'].values\n",
        "\n",
        "print(\"\\n--- Contoh Data setelah Preprocessing ---\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9erWk2c_kcQ",
        "outputId": "efcfdc2e-fcb8-4c05-a50b-95736ad26bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Inspeksi Data ---\n",
            "Labels\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Deskripsi Data:\n",
            "       Labels                     SMS\n",
            "count    5572                    5572\n",
            "unique      2                    5169\n",
            "top       ham  Sorry, I'll call later\n",
            "freq     4825                      30\n",
            "\n",
            "--- Contoh Data setelah Preprocessing ---\n",
            "   Labels                                                SMS\n",
            "0       0  Go until jurong point, crazy.. Available only ...\n",
            "1       0                      Ok lar... Joking wif u oni...\n",
            "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       0  U dun say so early hor... U c already then say...\n",
            "4       0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langkah 3**"
      ],
      "metadata": {
        "id": "-fual32A_sRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# LANGKAH 3: EKSTRAKSI FITUR (BAG OF WORDS)\n",
        "# ==========================================\n",
        "\n",
        "# Split data training dan testing (80:20)\n",
        "# random_state=50 agar hasil konsisten\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "\n",
        "# Inisiasi CountVectorizer\n",
        "bow = CountVectorizer()\n",
        "\n",
        "# Fitting dan Transform pada X_train\n",
        "# Kita mempelajari kosakata (vocabulary) HANYA dari data training\n",
        "X_train = bow.fit_transform(X_train)\n",
        "\n",
        "# Transform pada X_test\n",
        "# Kita menggunakan kosakata yang dipelajari dari X_train untuk mengubah X_test.\n",
        "# Jangan pernah melakukan fit() pada data testing untuk mencegah Data Leakage.\n",
        "X_test = bow.transform(X_test)\n",
        "\n",
        "# Cek dimensi fitur\n",
        "# Menggunakan get_feature_names_out() karena get_feature_names() sudah deprecated di versi baru sklearn\n",
        "print(f\"\\nJumlah Fitur (Vocabulary): {len(bow.get_feature_names_out())}\")\n",
        "print(f\"Dimensi Data Training: {X_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUbc9WPL_vsv",
        "outputId": "2e859fea-0004-4d99-ba0f-653ded8ed4cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jumlah Fitur (Vocabulary): 7727\n",
            "Dimensi Data Training: (4457, 7727)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langkah 4**"
      ],
      "metadata": {
        "id": "awOZhz3y_zP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# LANGKAH 4: TRAINING DAN EVALUASI MODEL\n",
        "# ==========================================\n",
        "\n",
        "# Inisiasi Multinomial Naive Bayes\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "# Latih model dengan data training\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi data training\n",
        "y_pred_train = mnb.predict(X_train)\n",
        "\n",
        "# Prediksi data testing\n",
        "y_pred_test = mnb.predict(X_test)\n",
        "\n",
        "# Evaluasi Akurasi\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(f'\\n--- Hasil Evaluasi Multinomial Naive Bayes ---')\n",
        "print(f'Akurasi Data Train : {acc_train}')\n",
        "print(f'Akurasi Data Test  : {acc_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9ad2ZmC_1xl",
        "outputId": "75cc1733-9e6f-4773-f004-4ed367ca3a59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hasil Evaluasi Multinomial Naive Bayes ---\n",
            "Akurasi Data Train : 0.9946152120260264\n",
            "Akurasi Data Test  : 0.9775784753363229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer (Bag of Words): Teknik ini mengubah teks menjadi matriks angka. Setiap kata unik dalam seluruh data training dianggap sebagai satu fitur. Jika sebuah SMS mengandung kata tersebut, nilainya bertambah. Inilah mengapa disebut data multinomial (berbasis cacahan/frekuensi)."
      ],
      "metadata": {
        "id": "YsR04gVx_7zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengapa fit_transform hanya di Train? Ini adalah konsep Data Leakage. Jika kita melakukan fit pada data Test, model akan \"mengintip\" kata-kata yang ada di masa depan (data ujian). Kita harus berpura-pura bahwa data Test adalah data baru yang belum pernah dilihat sistem sebelumnya, sehingga kita hanya menggunakan kosakata yang dipelajari dari Train."
      ],
      "metadata": {
        "id": "JKRODxud_8pV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil Akurasi Tinggi: Hasil akurasi ~97% pada data test menunjukkan bahwa algoritma Naive Bayes sangat efektif untuk klasifikasi teks sederhana seperti Spam vs Ham, karena kata-kata dalam spam (misal: \"win\", \"free\", \"prize\") cenderung memiliki probabilitas kemunculan yang sangat berbeda dibandingkan SMS biasa."
      ],
      "metadata": {
        "id": "rh-70BFz__Cq"
      }
    }
  ]
}