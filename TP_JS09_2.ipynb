{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuRWZBc9Lvumcu0I1SPVnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emkafie/Machine-Learning/blob/main/TP_JS09_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas 2**"
      ],
      "metadata": {
        "id": "mcgLTSlhE2Pg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Langkah 1: LOAD & PREPROCESSING DATA**"
      ],
      "metadata": {
        "id": "IUDqjyZzFWUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vq1QDj-wErAh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. LOAD & PREPROCESSING DATA\n",
        "# ==========================================\n",
        "# Memuat data\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Drop kolom yang tidak perlu\n",
        "df = df.drop(df.iloc[:, 2:], axis=1)\n",
        "\n",
        "# Rename kolom agar lebih jelas\n",
        "df.rename(columns={'v1': 'Labels', 'v2': 'SMS'}, inplace=True)\n",
        "\n",
        "# Encoding Label (spam=1, ham=0)\n",
        "new_labels = {'spam': 1, 'ham': 0}\n",
        "df['Labels'] = df['Labels'].map(new_labels)\n",
        "\n",
        "# Memisahkan Fitur dan Label\n",
        "X = df['SMS'].values\n",
        "y = df['Labels'].values\n",
        "\n",
        "# Split Data (80% Train, 20% Test)\n",
        "# Menggunakan random_state yang sama agar perbandingan adil\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
      ],
      "metadata": {
        "id": "DrIneRxjFdJU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **COUNTVECTORIZER DENGAN STOP WORDS**"
      ],
      "metadata": {
        "id": "A_cvdMGGFlZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- EVALUASI MODEL 1: COUNTVECTORIZER ---\")\n",
        "\n",
        "# Inisiasi CountVectorizer dengan stop_words enabled\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Fitting dan Transform\n",
        "X_train_cv = cv.fit_transform(X_train)\n",
        "X_test_cv = cv.transform(X_test)\n",
        "\n",
        "# Training Model Multinomial Naive Bayes\n",
        "mnb_cv = MultinomialNB()\n",
        "mnb_cv.fit(X_train_cv, y_train)\n",
        "\n",
        "# Prediksi & Evaluasi\n",
        "y_pred_cv = mnb_cv.predict(X_test_cv)\n",
        "acc_cv = accuracy_score(y_test, y_pred_cv)\n",
        "\n",
        "print(f\"Akurasi (CountVectorizer): {acc_cv:.4f}\")\n",
        "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred_cv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5d7DBgFtqg",
        "outputId": "c94d7201-3e6d-474a-ae1b-2aa506b440d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- EVALUASI MODEL 1: COUNTVECTORIZER ---\n",
            "Akurasi (CountVectorizer): 0.9830\n",
            "Laporan Klasifikasi:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       954\n",
            "           1       0.98      0.90      0.94       161\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.95      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF-IDF DENGAN STOP WORDS**"
      ],
      "metadata": {
        "id": "PCb1c1pzFyMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- EVALUASI MODEL 2: TF-IDF ---\")\n",
        "\n",
        "# Inisiasi TfidfVectorizer dengan stop_words enabled\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fitting dan Transform\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Training Model Multinomial Naive Bayes\n",
        "mnb_tfidf = MultinomialNB()\n",
        "mnb_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi & Evaluasi\n",
        "y_pred_tfidf = mnb_tfidf.predict(X_test_tfidf)\n",
        "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "\n",
        "print(f\"Akurasi (TF-IDF): {acc_tfidf:.4f}\")\n",
        "print(\"Laporan Klasifikasi:\\n\", classification_report(y_test, y_pred_tfidf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA0kBy92F1dI",
        "outputId": "8302c32d-7895-4c6b-cbd9-800dbde8418b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- EVALUASI MODEL 2: TF-IDF ---\n",
            "Akurasi (TF-IDF): 0.9605\n",
            "Laporan Klasifikasi:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       954\n",
            "           1       1.00      0.73      0.84       161\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PERBANDINGAN**"
      ],
      "metadata": {
        "id": "hHwLRnhrF5gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- PERBANDINGAN HASIL ---\")\n",
        "print(f\"Akurasi CountVectorizer : {acc_cv:.4f}\")\n",
        "print(f\"Akurasi TF-IDF          : {acc_tfidf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgP_GtRpF8Jw",
        "outputId": "bd2e9d6a-206f-496c-c957-7cb3b2720709"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- PERBANDINGAN HASIL ---\n",
            "Akurasi CountVectorizer : 0.9830\n",
            "Akurasi TF-IDF          : 0.9605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kesimpulan Analisis**"
      ],
      "metadata": {
        "id": "pCtvtQJrGp7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words: Penggunaan stop_words='english' pada kedua metode berfungsi untuk menghilangkan kata-kata umum (seperti \"the\", \"is\", \"at\") yang tidak memiliki makna spesifik dalam menentukan apakah sebuah pesan adalah spam atau bukan. Hal ini membantu mengurangi dimensi fitur dan kebisingan (noise) data."
      ],
      "metadata": {
        "id": "j-CBLfshGn1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perbandingan Akurasi:\n",
        "\n",
        "* Model dengan CountVectorizer cenderung menghasilkan akurasi yang sedikit lebih tinggi atau setara dibandingkan model dengan TF-IDF pada kasus deteksi spam SMS ini.\n",
        "\n",
        "* Model dengan TF-IDF seringkali memiliki performa sedikit di bawah CountVectorizer dalam mendeteksi kelas minoritas (Spam) pada dataset teks pendek seperti SMS. Hal ini karena TF-IDF memberikan bobot lebih rendah pada kata yang sering muncul. Padahal, dalam kasus Spam, kata-kata kunci tertentu (misal: \"Free\", \"Win\") mungkin sering muncul di banyak data latih spam dan frekuensi kemunculan tersebut justru menjadi indikator kuat."
      ],
      "metadata": {
        "id": "YfAoc3gYGu6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan Fitur Terbaik: Untuk kasus dataset spam.csv ini, fitur CountVectorizer (Bag of Words) terbukti lebih optimal dibandingkan TF-IDF. Alasannya adalah teks SMS cenderung pendek dan penggunaan kata-kata spam sangat spesifik. Frekuensi kemunculan kata secara mentah (raw count) yang disediakan oleh CountVectorizer sudah cukup kuat untuk membedakan antara spam dan ham tanpa perlu pembobotan invers dokumen yang dilakukan oleh TF-IDF."
      ],
      "metadata": {
        "id": "9rDMVCz_Gyv7"
      }
    }
  ]
}