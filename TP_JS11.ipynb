{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11FNMO43Vx4fgOMEr-VHcTs-NxvopepqS",
      "authorship_tag": "ABX9TyONJUalme2ABdiPcxHUW9q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emkafie/Machine-Learning/blob/main/TP_JS11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas**"
      ],
      "metadata": {
        "id": "CADMxVBPa8Df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Klasifikasi Data Voice**"
      ],
      "metadata": {
        "id": "zrQzNNqDbCfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pathlib import Path\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "metadata": {
        "id": "oxGPwBbTbAnQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNRdI9e7VX1l",
        "outputId": "848c9e6a-47e4-4a45-8b77-828cc1f260e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Hasil Perbandingan Performansi Model SVM ---\n",
            "  Split Rasio  Kernel   Akurasi\n",
            "0       70:30  linear  0.970557\n",
            "1       70:30    poly  0.957939\n",
            "2       70:30     rbf  0.981073\n",
            "3       80:20  linear  0.976341\n",
            "4       80:20    poly  0.971609\n",
            "5       80:20     rbf  0.982650\n"
          ]
        }
      ],
      "source": [
        "# 1. Load Data\n",
        "try:\n",
        "    df = pd.read_csv('voice.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"File voice.csv tidak ditemukan. Pastikan file berada di direktori yang sama.\")\n",
        "    exit()\n",
        "\n",
        "# 2. Preprocessing\n",
        "# Encoding label (Male/Female -> 1/0)\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['label'])\n",
        "\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "# 3. Definisi Skenario\n",
        "ratios = [0.3, 0.2] # 0.3 artinya 70:30, 0.2 artinya 80:20\n",
        "kernels = ['linear', 'poly', 'rbf']\n",
        "results = []\n",
        "\n",
        "# 4. Loop Training dan Evaluasi\n",
        "for test_size in ratios:\n",
        "    # Split Data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Scaling (Penting untuk SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    split_name = f\"{int((1-test_size)*100)}:{int(test_size*100)}\"\n",
        "\n",
        "    for kernel in kernels:\n",
        "        # Inisiasi dan Training Model\n",
        "        svm = SVC(kernel=kernel)\n",
        "        svm.fit(X_train, y_train)\n",
        "\n",
        "        # Prediksi dan Akurasi\n",
        "        y_pred = svm.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Simpan Hasil\n",
        "        results.append({\n",
        "            'Split Rasio': split_name,\n",
        "            'Kernel': kernel,\n",
        "            'Akurasi': acc\n",
        "        })\n",
        "\n",
        "# 5. Tabulasi Hasil\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"--- Hasil Perbandingan Performansi Model SVM ---\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Preprocessing: Data label diubah menjadi numerik dan fitur distandarisasi menggunakan StandardScaler. Standarisasi sangat krusial karena SVM sensitif terhadap skala data.\n",
        "\n",
        "* Looping Skenario: Program melakukan iterasi untuk rasio split 70:30 dan 80:20. Di dalam setiap split, tiga kernel (Linear, Poly, RBF) dilatih.\n",
        "\n",
        "* Tabel Hasil: Output menampilkan tabel dengan kolom Split Rasio, Kernel, dan Akurasi. Biasanya, kernel RBF atau Linear memberikan hasil yang sangat kompetitif pada dataset ini (di atas 97%), sementara kernel Polynomial mungkin membutuhkan waktu komputasi lebih lama tergantung derajat polinomialnya."
      ],
      "metadata": {
        "id": "Y9-DH40ubUsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Klasifikasi Citra (Siang/Malam) dengan Histogram**"
      ],
      "metadata": {
        "id": "5rOJWu0sbdm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. FUNGSI EKSTRAKSI FITUR HISTOGRAM\n",
        "# ==========================================\n",
        "def extract_histogram_feature(img_dir):\n",
        "    p = Path(img_dir)\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Mapping label string ke angka\n",
        "    # day -> 1, night -> 0\n",
        "\n",
        "    for folder in p.glob('*'):\n",
        "        label_str = str(folder).split(os.sep)[-1]\n",
        "        label = 1 if label_str == 'day' else 0\n",
        "\n",
        "        for file in folder.glob('*.jpg'):\n",
        "            img = cv2.imread(str(file))\n",
        "            if img is not None:\n",
        "                # Resize untuk konsistensi (opsional jika menggunakan histogram, tapi baik untuk performa)\n",
        "                img = cv2.resize(img, (200, 200))\n",
        "\n",
        "                # Menghitung Histogram untuk setiap channel (B, G, R)\n",
        "                # 32 bins per channel cukup untuk menangkap distribusi warna tanpa terlalu banyak fitur\n",
        "                hist_features = []\n",
        "                colors = ('b', 'g', 'r')\n",
        "                for i, col in enumerate(colors):\n",
        "                    # Hitung histogram: channel i, mask None, 32 bins, range 0-256\n",
        "                    hist = cv2.calcHist([img], [i], None, [32], [0, 256])\n",
        "                    # Normalisasi histogram agar tidak terpengaruh ukuran gambar\n",
        "                    cv2.normalize(hist, hist)\n",
        "                    hist_features.extend(hist.flatten())\n",
        "\n",
        "                features.append(hist_features)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD DATA & SPLIT\n",
        "# ==========================================\n",
        "# Menggabungkan data train dan test folder untuk displit ulang sesuai instruksi (80:20)\n",
        "base_dir = \"/content/drive/MyDrive/Machine Learning/images/\"\n",
        "\n",
        "# Cek keberadaan folder\n",
        "if os.path.exists(base_dir):\n",
        "    # Ekstraksi fitur dari folder training dan test (digabung lalu di-reshuffle)\n",
        "    X_part1, y_part1 = extract_histogram_feature(base_dir + \"training\")\n",
        "    X_part2, y_part2 = extract_histogram_feature(base_dir + \"test\")\n",
        "\n",
        "    X = np.concatenate((X_part1, X_part2), axis=0)\n",
        "    y = np.concatenate((y_part1, y_part2), axis=0)\n",
        "\n",
        "    print(f\"Total Data: {X.shape[0]}, Jumlah Fitur per Gambar: {X.shape[1]}\")\n",
        "\n",
        "    # Split Data 80:20\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scaling Data (Wajib untuk SVM)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. HYPERPARAMETER TUNING (GRIDSEARCH)\n",
        "    # ==========================================\n",
        "    print(\"\\nMemulai Grid Search...\")\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [1, 0.1, 0.01, 0.001],\n",
        "        'kernel': ['rbf']\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=3)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # ==========================================\n",
        "    # 4. EVALUASI\n",
        "    # ==========================================\n",
        "    print(\"\\n--- Hasil Terbaik ---\")\n",
        "    print(f\"Parameter Terbaik: {grid.best_params_}\")\n",
        "\n",
        "    grid_predictions = grid.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, grid_predictions)\n",
        "\n",
        "    print(f\"Akurasi Model (Kernel RBF + Histogram): {accuracy:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"Folder 'images' tidak ditemukan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNqmg8ZrbgbE",
        "outputId": "2f3eac57-5914-413d-a137-c7f976c7ec31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Data: 400, Jumlah Fitur per Gambar: 96\n",
            "\n",
            "Memulai Grid Search...\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "\n",
            "--- Hasil Terbaik ---\n",
            "Parameter Terbaik: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Akurasi Model (Kernel RBF + Histogram): 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekstraksi Fitur Histogram:\n",
        "* Berbeda dengan fitur rata-rata kecerahan, histogram menangkap sebaran warna. Fungsi cv2.calcHist digunakan untuk menghitung frekuensi kemunculan intensitas piksel.\n",
        "* Kode menggunakan 32 bins per kanal warna (R, G, B). Total fitur yang dihasilkan per gambar adalah $32 \\times 3 = 96$ fitur. Fitur ini kemudian dinormalisasi agar invarian terhadap ukuran gambar."
      ],
      "metadata": {
        "id": "0Z3diXvccjQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: Data dari folder training dan test digabung terlebih dahulu, kemudian dipecah kembali menggunakan train_test_split dengan rasio 80:20 sesuai instruksi soal."
      ],
      "metadata": {
        "id": "wMzNzlDjcnI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search:\n",
        "\n",
        "* Dilakukan pencarian parameter terbaik untuk C (penalti kesalahan) dan gamma (koefisien kernel RBF).\n",
        "\n",
        "* Output Parameter Terbaik menampilkan kombinasi hyperparameter yang menghasilkan skor validasi silang tertinggi."
      ],
      "metadata": {
        "id": "GlBL-9-dcptT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi Akhir:\n",
        "\n",
        "* Nilai akurasi pada data testing ditampilkan di akhir. Penggunaan fitur histogram pada SVM kernel RBF umumnya menghasilkan akurasi yang lebih tinggi dibandingkan hanya menggunakan rata-rata kecerahan, karena histogram mampu membedakan karakteristik warna \"siang\" (biru langit, awan putih) dan \"malam\" (gelap, lampu kuning) dengan lebih detail."
      ],
      "metadata": {
        "id": "k6eGXuvvctpX"
      }
    }
  ]
}